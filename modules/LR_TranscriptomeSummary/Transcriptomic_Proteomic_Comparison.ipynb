{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile Key Transcriptomic Information ##\n",
    "# Prepare two tables:\n",
    "# 1. Sqanti Isoform Table \n",
    "# 2. Gene Based Info Tabe \n",
    "\n",
    "#### Import Modules ####\n",
    "# Python Modules #\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "#### Input Files ####\n",
    "sqanti_out = '../../data/jurkat_classification.txt'\n",
    "tpm_file =  '../../data/jurkat_gene_kallisto.tsv'\n",
    "ribodep_tpm = '../../data/kallist_table_rdeplete_jurkat.tsv' # expects normalized data\n",
    "ensg_to_gene = \"../../results/PG_ReferenceTables/ensg_to_gene.tsv\"\n",
    "enst_to_isoname = \"../../results/PG_ReferenceTables/enst_to_isoname.tsv\"\n",
    "gene_len_stats_tab =  '../../results/PG_ReferenceTables/gene_len_stats.tsv'\n",
    "\n",
    "#### Outputs ###\n",
    "# 1. Sqanti_isoform_table\n",
    "# 2. Gene_level_info_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Part 1 : Prepare Isoform Information Table from sqanti Output ####\n",
    "\n",
    "def sqtab(sqanti_out, ensg_to_gene, enst_to_isoname):\n",
    "    \"\"\"\n",
    "    Sorts data from Sqanti output \n",
    "    \"\"\"\n",
    "\n",
    "    # Import Sqanti Output File\n",
    "    cols = ['isoform', 'length', 'structural_category','associated_gene','associated_transcript','subcategory', 'FL', 'coding','ORF_length', 'CDS_start', 'CDS_end', 'predicted_NMD']\n",
    "    data = pd.read_csv(sqanti_out, delimiter=\"\\t\", usecols = cols)\n",
    "    data.columns = ['pb_acc', 'len', 'cat', 'gene','transcript', 'cat2', 'fl_cts','coding', 'orf_len', 'cds_st','cds_end', 'nmd']\n",
    "\n",
    "    # Convert Structural Categories to Acronyms\n",
    "    data.replace({\"novel_not_in_catalog\":\"NNC\",\"novel_in_catalog\":\"NIC\",\"incomplete-splice_match\":\"ISM\",\"full-splice_match\":\"FSM\"}, inplace = True)\n",
    "\n",
    "    # Filter out any cat that is not FSM, ISM, NNC or NIC\n",
    "    f= ['FSM', 'ISM', 'NNC', \"NIC\"]\n",
    "    fdata = data[data.cat.isin(f)]\n",
    "\n",
    "    # Normalize fl_cts to cpm \n",
    "    sum = fdata['fl_cts'].sum(skipna=True)\n",
    "    fdata['cpm'] = 1000000*fdata['fl_cts']/sum\n",
    "\n",
    "    # Define 5'UTR and 3'UTR\n",
    "    UTR5_len = fdata['cds_st'] - 1\n",
    "    UTR3_len = fdata['len'] - fdata['cds_end'] + 1\n",
    "\n",
    "    # Add 5'UTR and 3'UTR Information to Table\n",
    "    fdata.insert(loc=len(fdata.columns), column = \"5utr_len\", value = UTR5_len)\n",
    "    fdata.insert(loc=len(fdata.columns), column = \"3utr_len\", value = UTR3_len)\n",
    "\n",
    "    ## Finding and Replacing Gene Information ##\n",
    "    # Import Human Readable Gene Info and rename columns\n",
    "    gen_name = pd.read_csv(ensg_to_gene, delimiter=\"\\t\", header=None)\n",
    "    gen_name.columns = ['A', 'B']\n",
    "\n",
    "    # Make a Dictionary with Columns A and B\n",
    "    gdict = pd.Series(gen_name.B.values,index=gen_name.A).to_dict()\n",
    "\n",
    "    # Use Dictionary to Find Gene Names and Replace them with Human Readable Genes\n",
    "    df = fdata[['gene']]\n",
    "    fdata['gene'] = fdata['gene'].map(gdict).fillna(fdata['gene'])\n",
    "    fdata.drop(fdata[fdata['gene'] == df['gene']].index, inplace=True)\n",
    "  \n",
    "    ## Finding and Replacing Transcript Information ##\n",
    "    # Import Human Readable Transcript Info and rename columns\n",
    "    trans = pd.read_csv(enst_to_isoname, delimiter=\"\\t\", header=None)\n",
    "    trans.columns = ['A', 'B']\n",
    "\n",
    "    # Make a Dictionary and Replace Transcript Names\n",
    "    tdict = pd.Series(trans.B.values, index=trans.A).to_dict()\n",
    "    fdata['transcript'] = fdata['transcript'].map(tdict).fillna(fdata['transcript'])\n",
    "\n",
    "    # Write Dataframe as TSV File\n",
    "\n",
    "    fdata.to_csv(\"../../results/LR_TranscriptomeSummary/sqanti_isoform_tab.tsv\", sep=\"\\t\", index= False, na_rep='0')\n",
    "    return fdata\n",
    "\n",
    "    print(\"Isoform Table from sqanti output has been prepared\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Part 3: Abundace Data by Gene ####\n",
    "def abund(sq_isotab, tpm_file):\n",
    "    \"\"\"\n",
    "    Prepare a gene, cpm, tpm table from sqanti and kallisto output\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort CPM Data\n",
    "    cpm_data = sq_isotab[['gene', 'cpm']]\n",
    "    cpm_by_gene = cpm_data.groupby(['gene']).agg(cpm = ('cpm', 'sum')).reset_index(level=['gene'])\n",
    "\n",
    "    # Sort Illumina Data\n",
    "    tpm_by_gene = pd.read_csv(tpm_file, delimiter='\\t')\n",
    "    tpm_by_gene['gene'] = tpm_by_gene['gene'].str.replace('-', '_')\n",
    "\n",
    "    # Merge\n",
    "    ab = pd.merge(cpm_by_gene, tpm_by_gene, how='right', on='gene')\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Part 4: Include PolyA Tail Info ####\n",
    "\n",
    "def polyA(ribodep_tpm)\n",
    "\n",
    "## Ribodepletion Data ##\n",
    "ribo = pd.read_csv(ribodep_tpm, sep='\\t')\n",
    "rgen = ribo.groupby(['gene']).agg(rtpm=('tpm', 'sum')).reset_index()\n",
    "rgen['log(rtpm+1)'] = np.log10(rgen['rtpm'] + 1)\n",
    "\n",
    "# Add 1 to tpm data #\n",
    "tpm_by_gene['log(tpm+1)'] = np.log10(tpm_by_gene['tpm'] + 1)\n",
    "\n",
    "# Merge and calc rtpm/tpm on log scale\n",
    "pA = pd.merge(rgen, tpm_by_gene, how = 'outer', on='gene')\n",
    "pA['ratio'] = pA['log(rtpm+1)']/pA['log(tpm+1)']\n",
    "#npA = pA[pA['ratio']>120].reset_index()\n",
    "\n",
    "# Add PolyA info to Gene Length table \n",
    "#pA_gen = gen_lenab.assign(r_ispolyA =~ gen_lenab.gene.isin(npA.gene))\n",
    "\n",
    "# Output Gene-Level Table \n",
    "#pA_gen.to_csv(gen_level_tab, sep='\\t', index=False, na_rep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If results folder does not exist, make it\n",
    "rdir = '../../results/LR_TranscriptomeSummary'\n",
    "if not os.path.exists(rdir):\n",
    "    os.mkdir(rdir)\n",
    "\n",
    "# Make Sqanti Table \n",
    "sq_isotab = sqtab(sqanti_out, ensg_to_gene, enst_to_isoname)\n",
    "\n",
    "# Make Abundance Table and Merge with Gene_Length_Stats Table \n",
    "ab_tab = abund(sq_isotab, tpm_file)\n",
    "gene_len_stats = pd.read_csv(gene_len_stats_tab, sep = '\\t')\n",
    "gen_lenab = pd.merge(gene_len_stats, ab_tab, how=\"right\", on='gene')\n",
    "\n",
    "# Make and Merge with PolyA Table \n",
    "ribo = pd.read_csv(ribodep_tpm, sep='\\t')\n",
    "rgen = ribo.groupby(['gene']).agg(rtpm=('tpm', 'sum')).reset_index()\n",
    "#rgen['log(rtpm+1)'] = np.log10(rgen['rtpm'] + 1)\n",
    "#ab_tab['log(tpm+1)'] = np.log10(ab_tab['tpm'] + 1)\n",
    "ratio = pd.merge(rgen, ab_tab, how = 'left', on='gene')\n",
    "ratio['rtpm/tpm'] = ratio['rtpm']/ratio['tpm']\n",
    "ratio_tab = ratio[['gene', 'rtpm/tpm']]\n",
    "gen_tab = pd.merge(gen_lenab, ratio_tab, how='left', on='gene')\n",
    "\n",
    "# Output Table \n",
    "gen_tab.to_csv(\"../../results/LR_TranscriptomeSummary/sqanti_isoform_tab.tsv\", sep=\"\\t\", index= False, na_rep='0')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}